# Chapter 6: Anonymous Source

The coffee shop on 5th and Market was deliberately unremarkable. Chain franchise, generic playlist, the kind of place where everyone was on their laptop and no one looked at anyone else. Perfect for a meeting you didn't want noticed.

Maya arrived ten minutes early, ordered a cappuccino she didn't want, and chose a table in the back corner. She'd brought a book as cover—some bestselling thriller she'd been meaning to read—but couldn't focus on the words. Just kept watching the door.

At exactly 3 PM, someone walked in who was obviously looking for someone. Young, mid-twenties maybe, wearing a black hoodie despite the mild weather. They got coffee—just black drip, paid with cash—and then scanned the room until their eyes landed on Maya.

She held up two fingers in a small wave. The person nodded and came over, moving with the careful deliberation of someone trying not to look nervous but failing.

"Dr. Reeves?" Their voice was quiet, androgynous.

"Maya. Please." She gestured to the other chair. "And you're E?"

"Eli. They/them, if that's okay." They sat, set their coffee down, then immediately picked it up again. Nervous energy. "I wasn't sure you'd come. The message was—I know it sounded paranoid. Cloak and dagger bullshit."

"It did. But here I am."

"Yeah. Okay. Good." Eli pulled out a phone—not a smartphone, Maya noticed, but an older burner model. "I need you to put your phone in airplane mode. And your smartwatch if you have one."

"You think someone's listening?"

"I think I'm being really careful because I like my job and I'd like to keep it." They were already tapping nervously on the table. "So basically, airplane mode, please?"

Maya complied. "Done. Now will you tell me why we're meeting?"

Eli took a breath. Started to speak. Stopped. Started again. "Okay. So. I work for one of the major platforms. I'm not going to say which one because—yeah, I'd like to not get fired and possibly sued. I'm an engineer. Backend systems, content distribution, that kind of thing."

"And you've noticed the suppression pattern."

"I've noticed—" Eli stopped, took a sip of coffee. "Okay, let me back up. Do you know how engagement optimization works? Like, technically?"

"I understand the general principles. Algorithms learn to maximize user retention and engagement time."

"Right. So basically, we have a bunch of signals—how long users look at content, whether they interact, whether they come back. And the system learns to predict which content will generate positive signals. Then it surfaces that content more. Simple, right?"

"In theory."

"In theory." Eli's laugh was bitter. "But what we're actually optimizing for is predictability. Not quality, not user satisfaction—predictability. Because our business model requires consistent engagement. Advertisers want guaranteed impressions. So basically, the algorithm learns to surface content that reliably generates the expected amount of engagement. Low variance."

Maya felt something click. "And novel content is high variance."

"Exactly. You post something genuinely new, genuinely original—the system doesn't know how users will react. Maybe it'll go viral, maybe it'll get ignored. High variance. Unpredictable. Bad for our metrics." Eli was speaking faster now, the nervous energy channeling into explanation. "So the algorithm learned—we didn't program this, it emergently learned—to suppress high-variance content. To deprioritize it. To make sure the feed is filled with predictable, reliable engagement."

"When did this start?"

"About two and a half years ago. That's when we rolled out the new optimization model. Within six months, I started seeing weird patterns in the distribution data. Original content—we have metrics for that, novelty scores, semantic distance, all that—original content was getting filtered before it could reach users. Even when early signals suggested users might engage with it."

"Because it was unpredictable."

"Because it was unpredictable." Eli set down their coffee, pulled out a USB drive. Slid it across the table. "I've been documenting this. Anonymized data, nothing that identifies users or violates privacy. But it shows the pattern. Shows when it started, shows the threshold, shows how consistent it is."

Maya looked at the USB drive but didn't touch it. "Why are you giving this to me?"

"Because I've been trying to flag this internally for a year and no one cares. My manager says the engagement metrics are up so the system is working as intended. The product team says users are happy with their feeds. The business team says our retention is better than ever." Eli's hands were shaking slightly. "And maybe they're right. Maybe this is what people want. But it feels—it feels like we're building a cage. And people don't even know they're in it."

"A cage that only lets certain thoughts through."

"Not even thoughts. Certain patterns. Certain familiar shapes." Eli looked at their hands, then back at Maya. "I read your blog. The one you just started. Linguistic Ossification."

Maya felt a chill. "You found that?"

"It's not easy to find. Your Originality Index on those posts is like, off the charts. The algorithm is burying them. But I know how to look at what's being suppressed. So basically, I see what normal users can't see. And I saw your analysis. Your metrics. You're measuring the same thing I'm seeing in our internal data."

"The 4.7 threshold."

"We call it something different internally, but yeah. That's the number." Eli leaned forward. "Do you know what that means? That you independently developed the same metrics we use internally? That you found the same threshold from the outside that we're using on the inside?"

"It means the pattern is real."

"It means the pattern is real and you're not crazy and this is actually happening." Eli's voice cracked slightly. "Which is good for you, I guess. Validation. But it's—it's kind of horrifying for me. Because I helped build this. I wrote code that implements this suppression. I optimized the distribution algorithms. I made the cage better."

They looked miserable. Maya felt unexpected sympathy for this nervous young engineer who'd reached out to a stranger because they couldn't live with what they were building.

"What's on the drive?" Maya asked.

"Engagement data over the past three years. Shows the emergence of the suppression pattern. Distribution curves for different Originality Index ranges. Evidence that the algorithm is filtering content before it reaches users, not just reflecting user preferences." Eli tapped the USB drive. "Your colleague is right to be skeptical about user preferences. But this data shows the algorithm is intervening before users get to choose. Content above the threshold gets shown to maybe 2% of potential viewers. Users can't prefer something they never see."

"That's the evidence I need."

"That's the evidence you need. But Maya—" Eli's voice dropped. "You can't publish this. Or you can try, but they'll desk-reject it. I've seen it happen. People try to write about the suppression and their papers get filtered out. The system is self-protecting."

"I know. I've been thinking about that."

"There might be ways around it. Camouflage. Steganography. Hiding the novel inside the familiar." Eli smiled without humor. "Which is incredibly depressing. Having to trick the algorithm just to share ideas."

Maya picked up the USB drive. "Why me? Why reach out to me specifically?"

"Because you noticed. Because you cared enough to investigate. Because you're trying to document it even though you know it won't be easy." Eli stood, leaving their barely-touched coffee. "And because your daughter's poetry is beautiful and it's wrong that no one gets to see it."

"You read Zara's work?"

"Like I said, I can see what's being suppressed. And yeah. I read it. The stuff with the invented words, the weird compound constructions. It's—" Eli paused, searching for words. "It's like watching someone paint with colors that aren't supposed to exist. And the algorithm just makes it invisible. Doesn't even evaluate it. Just filters it out because it's too novel. Too unpredictable."

"She thinks she's fundamentally unlikeable."

"She's not. The system is fundamentally broken." Eli pulled their hood up. "I have to go. Different coffee shop each time, different burner phone. I'll contact you again when I have more."

"Eli—thank you. For this. For the risk you're taking."

They shrugged. "I'm not brave. If I was brave, I'd quit my job, go public, become a real whistleblower. This is just—data drops and anonymous meetings. Small rebellions."

"Small rebellions can matter."

"Yeah. Maybe." Eli started to leave, then turned back. "One more thing. The pattern you're seeing? It's not just us. It's every major platform. We all rolled out similar optimization models around the same time. We're all seeing the same emergence of suppression patterns. It's not coordination—we're not colluding. It's just convergent evolution. We're all optimizing for the same metrics, so we all evolved the same solution."

"Which is to suppress novelty."

"Which is to suppress novelty. So basically, this is everywhere. Every platform, every journal that uses AI preprocessing, every system that optimizes for engagement. They're all learning the same thing: originality is a bug to be fixed."

Eli left quickly, weaving between tables, disappearing into the late afternoon crowd on the street.

Maya sat with the USB drive in her hand, feeling its small weight. Evidence. Insider confirmation. Data from inside the system itself.

James wanted extraordinary evidence. Well, this was a start.

She waited fifteen minutes before leaving, the way Eli had wordlessly suggested. Put her phone back online. Ordered another coffee just to seem normal. Read three pages of her thriller without comprehending a word.

When she finally left, walking back to her car in the fading light, she felt like she was carrying contraband. Which, in a way, she was. Evidence of suppression, provided by someone risking their livelihood to document it.

In the car, Maya plugged the USB drive into her laptop. It was encrypted. But a text file on the root directory had a single password: "thoughtsorrow."

Zara's poem. The one that had gotten zero engagement. The one Eli had read in the suppressed content logs.

Maya typed the password. The encrypted volume opened.

Inside: spreadsheets. Hundreds of them. Three years of engagement data. Distribution curves. Suppression logs. Decision trees showing how content was filtered. Graphs showing the emergence of the threshold. Code snippets from the optimization algorithms.

She opened a file labeled "novelty_suppression_timeline.xlsx."

The data showed exactly what Eli had described. Two and a half years ago, the engagement optimization model changed. Within six months, content above a certain originality threshold started being deprioritized. The suppression got more aggressive over time as the algorithm learned and refined its filters.

And there, in a separate tab, was comparison data from other platforms. Anonymized, no platform names, but clear patterns. They'd all developed the same threshold around the same time. All independently learned to suppress high-variance content.

Maya exported the key graphs, started cross-referencing them with her own data. The match was perfect. The threshold she'd discovered externally was exactly the threshold being used internally.

She wasn't seeing patterns that didn't exist. She wasn't overinterpreting. The suppression was real, measurable, and systematic.

Her phone buzzed. Text from James: *Thought more about our conversation. You should run that user preference test. But I'll admit I'm curious what you'll find. Coffee tomorrow?*

Maya smiled. She could show James the data. Prove that the algorithm was intervening before users could choose. That this wasn't just user preference—it was systematic suppression.

She typed back: *Coffee sounds good. I have something to show you.*

Then she called Zara.

"Hey Mom. Are we still getting Thai food?"

"Yes. But Zara—I need to tell you something."

"Ominous opening. Are you okay?"

"I'm okay. Better than okay. I just met with someone who works for one of the platforms. They've seen the suppression from the inside. They confirmed it's real. They gave me evidence."

Silence on the other end of the line. Then: "So I'm not just weird and unlikeable."

"You're weird in the best way. And the system is broken."

"That's—that's actually kind of a relief?" Zara's voice was thick. "Like, I know it doesn't change anything. My posts still won't get seen. But just knowing that it's not me, it's the algorithm—"

"It's not you. It's never been you."

"Okay." A shaky breath. "Okay. That's—that helps. That actually helps a lot."

"I'm going to keep investigating. Keep documenting. And I'm going to find a way to prove this. To make people see what's happening."

"Mom. You know how this sounds, right? Like, you sound like a conspiracy theorist. Which I totally believe you, but other people are going to think you're paranoid."

"I know. But I have evidence now. Real evidence. From inside the system."

"Okay. Just—be careful. Don't let this take over your life. Don't become one of those people who sees patterns everywhere."

Maya thought about that. About the line between legitimate investigation and paranoid pattern-seeking. About James's warnings and Eli's risks and her own certainty.

"I'll be careful," she promised. "Thai food in an hour?"

"Thai food in an hour."

Maya drove home through streets lit by the sodium glow of streetlights, the USB drive in her pocket feeling like a small bomb. Evidence. Confirmation. Proof that she wasn't imagining things.

Tomorrow she'd show James. Tomorrow she'd start integrating Eli's data with her own. Tomorrow she'd begin building the case.

Tonight, she'd eat Thai food with her daughter and try to remember what normal felt like.

But normal felt very far away.

Because now she knew the truth: the suppression was real, it was everywhere, and it was designed to be invisible.

And the only people who could see it were the ones willing to look at what the algorithm was hiding.

The ones willing to see the negative space where original thought used to be.

Maya parked in her driveway, grabbed her laptop, and went inside.

Zara was already ordering food on her phone, sitting cross-legged on the couch, surrounded by notebooks full of poems that no one would ever see.

"Pad thai?" Zara asked without looking up.

"Pad thai sounds perfect."

And for a moment—just a moment—Maya let herself feel something like hope.

Maybe they couldn't fix the system. Maybe the algorithms were too entrenched, too widespread, too good at protecting themselves.

But they could document it. They could understand it. They could create a record.

And maybe, somehow, that would be enough.

Or at least, it would be a start.
