# Chapter 9: Rosengård

The Enigma Market homepage loaded slowly through Tor routing, layer after layer of encryption peeling back to reveal a surprisingly professional interface. Emil had been navigating dark web markets for five years now, and they never stopped unsettling him—these polished storefronts selling tools for crime as casually as Amazon sold books.

NullGradient's vendor page had the clean aesthetic of a legitimate software company. Product descriptions, customer reviews, even a FAQ section. "Adversarial ML Toolkit v3.2 - Bypass facial recognition systems with 94% success rate. Includes pre-trained models for common surveillance platforms." Five hundred euros in cryptocurrency. Forty-seven five-star reviews.

Emil clicked through to the vendor's profile. Active since August. Specialization: surveillance and security system exploits. Response time: typically within four hours. Customer satisfaction: 98%. It read like a LinkedIn profile for criminal enterprise.

The forum section was more revealing. NullGradient wasn't just selling tools—they were teaching methodology. Long, detailed posts explaining adversarial attack theory, the mathematics of model poisoning, the ethics of exposing surveillance infrastructure vulnerabilities. One thread caught Emil's attention:

*"Most people don't realize they're training the systems that oppress them. Every time you walk past a camera, unlock your phone with your face, use a smart lock—you're generating training data. The algorithms learn your patterns, predict your behavior, optimize you into compliance. I'm not selling crime. I'm selling literacy. Understanding how these systems work is the first step to refusing their control."*

Below, dozens of replies. Some thank-yous from buyers. Some technical questions about implementation. And then a response from another vendor, username "Adversary":

*"Well said, Null. The surveillance infrastructure isn't just watching—it's shaping. Every optimization is also a constraint. Teaching people to see the algorithms is more valuable than any single exploit."*

Emil screenshotted the exchange. NullGradient and Adversary seemed to be collaborators, or at least ideological allies. Both focused on surveillance systems, both framing their work as resistance rather than crime. Both sophisticated enough to understand ML theory at a graduate level.

He ran linguistic analysis on both users' posts. Similar writing patterns—code-switching between technical jargon and accessible explanations, use of "we" when referring to marginalized communities, "they" when discussing institutions. Geographic and temporal correlation showed both users active during European hours, posting patterns consistent with Swedish time zones.

Rosengård kept coming up in the data. Not explicitly—NullGradient's operational security was too good for that. But the correlations were there. Forum activity timestamps, infrastructure vulnerabilities discussed (Swedish smart building systems, Malmö port automation), even the specific SecureWatch security model used across southern Sweden.

Emil pulled up a map of Malmö, colored to show internet infrastructure patterns. Rosengård lit up with activity—higher than average dark web traffic, encrypted messaging app usage, VPN adoption rates. Not surprising in an economically marginalized neighborhood where many residents had reason to avoid surveillance. But combined with the other data points...

His phone buzzed. Sara, texting from Rosengård: "Heading to community center. People are willing to talk but wary of police. This place feels like a different city."

Emil stared at the map, at the digital traces painting a picture of a neighborhood that didn't fit the smart city narrative Malmö loved to tell about itself. The gleaming rhetoric of optimization and efficiency stopped at Rosengård's borders. Here, people weren't benefiting from algorithmic governance—they were surviving it.

He typed back: "Be careful. If NullGradient is from there, they're not just smart. They're protective of community."

---

Rosengård in December felt colder than the rest of Malmö, though Sara knew that was psychological rather than meteorological. The neighborhood stretched out in organized blocks of apartment buildings, built in the 1970s with optimistic socialist efficiency and now home primarily to immigrants and refugees. Somali, Arabic, and Swedish mixed in the air as Sara walked past small shops—halal grocers, phone repair stands, internet cafes.

She'd dressed down, left her police badge in her pocket, tried to look like just another person navigating the afternoon. But she knew she stood out anyway. White, Swedish, obviously not from here. The kind of person who usually only came to Rosengård for official business.

The community center was a low brick building with hand-painted signs in multiple languages advertising ESL classes, job training, youth programs. Inside, a young woman at the reception desk looked up with practiced wariness.

"I'm looking for information about tech education programs," Sara said, keeping her voice casual. "I heard Rosengård has active computer science communities."

Not a lie, exactly. Just not the whole truth.

The receptionist relaxed slightly. "We have coding classes for youth. Some university students volunteer to teach." She pulled out a flyer. "Next session is Thursday evening."

"Do a lot of young people here study computer science?"

"Those who can." The receptionist's voice carried resignation. "We have smart kids, you know? Really smart. But university is expensive, and employers..." She shrugged. "They see Rosengård on your address, suddenly you're not qualified anymore. Doesn't matter what your grades are."

Sara had read the statistics. University enrollment rates in Rosengård were half the city average. Employment rates for computer science graduates were 30% lower for those from immigrant neighborhoods, even controlling for GPA. The algorithms that supposedly made hiring fair and objective turned out to encode the same biases as human recruiters—just faster, and at scale.

"So some of them find other ways to use their skills," Sara said carefully.

The receptionist met her eyes. "You're police."

"Economic crime division. I'm investigating algorithmic exploitation—criminals using ML and AI to bypass security systems. I think someone from Rosengård might be involved, but not necessarily as a perpetrator. Maybe as someone who understands these systems better than the people who built them."

A long silence. Then: "If someone from here did learn to beat those systems, would you blame them? When the systems are designed to keep us out?"

Sara thought about her father, about automation that was sold as progress but functioned as displacement. About algorithms that optimized profit by eliminating people. About the pharmacist she'd seen yesterday, about service workers becoming data exhaust, about entire classes of human beings deemed inefficient by machine learning models trained on decades of structural inequality.

"No," she said honestly. "I wouldn't blame them. But I still need to understand what's happening."

The receptionist considered this. "There's a café down the street. Rosengård Net. Tech kids hang out there. Maybe talk to them. But—" she leaned forward "—don't come in showing badge. Just talk. Listen. These kids aren't criminals. They're just trying to survive in a city that treats them like problems to be solved."

---

Rosengård Net was small and warm, smelling of coffee and electronic ozone. Half a dozen young people sat at tables with laptops, some working alone, others clustered in intense technical discussions. The walls were covered with posters—coding bootcamp advertisements, job fair announcements, a hand-drawn infographic explaining adversarial machine learning.

Sara bought coffee and sat near a group of three students arguing about neural network architectures. She listened, catching about half the technical terminology. One of them—a young woman in a hijab—was explaining gradient descent with the patience of someone who'd taught the concept many times before.

"...so the model minimizes loss by following the slope downward, but if you inject carefully crafted noise into the training data, you can create false minima that trap it in suboptimal solutions," she was saying. "That's how you poison a model. You make it confidently wrong."

"But detection is getting better," one of the others said. "Defensive distillation, gradient masking—"

"Only if you can access the training data to audit it," the young woman countered. "Most commercial systems are black boxes. You can probe them adversarially and map their decision boundaries without ever seeing inside."

She spoke with the authority of real expertise. Sara watched her, wondering. University student? Self-taught? Could this be—

The café door opened, bringing cold air and a man in his late twenties, carrying a backpack and talking on his phone in Somali. He waved to several of the laptop users, who waved back with obvious familiarity. Sara caught fragments of Swedish as he ordered coffee: "—just need to finish the deployment pipeline, then I'm free tonight—"

He sat down at a corner table, pulled out his own laptop, and disappeared into his screen. Sara watched him peripherally. Something about his ease here, the casual greetings, the way he settled into work like someone in his natural habitat. He could be anyone. A software developer, a student, a freelancer. Or he could be someone who'd learned to weaponize the systems that marginalized his community.

She couldn't approach him. No probable cause, no evidence, just a hunch based on geography and demographics. The kind of profiling she'd sworn not to do.

The young woman in the hijab packed up her laptop and left. Sara considered following, reconsidered. This wasn't how you built trust. This wasn't how you investigated communities—by treating everyone as suspects just because of where they lived.

Her phone buzzed. Emil: "Seven luxury apartment burglaries in Turning Torso and Västra Hamnen over the past six weeks. No forced entry. Smart building security showed no breaches. Same technical signature as pharmacy cases."

Sara's attention sharpened. Different crime, same methodology. Different perpetrators using similar tools, or the same person expanding operations?

She texted back: "Service workers?"

"Investigating now. But Sara—these buildings use SecureWatch for access control. Same randomization vulnerability."

The pattern was spreading. Or maybe it had always been there, and they were just now seeing it.

Sara looked around the café again. The man in the corner was coding something, his screen a cascade of text scrolling too fast to read. The remaining laptop users worked in companionable silence. Outside, Rosengård continued its daily rhythm—shops opening, buses running, people navigating systems that weren't designed for them but that they'd learned to navigate anyway.

Somewhere in this neighborhood, someone had learned to do more than navigate. Someone had learned to exploit, to teach, to distribute tools that turned surveillance infrastructure into vulnerability. And that someone was probably motivated by the same economic marginalization, the same algorithmic discrimination, the same structural inequality that Sara saw all around her.

She couldn't arrest a symptom and expect to cure a disease.

But she still needed to understand the scope. How many people were using these tools? How many crimes were being enabled? How far would this ecosystem spread?

---

That evening, Sara and Emil met in his forensics lab to compare findings. Sara described Rosengård—the tech-savvy youth, the economic barriers, the community protectiveness. Emil showed her the apartment burglary patterns.

"Seven high-value targets," he said, pulling up a map. "All in smart buildings built in the last three years. All using SecureWatch access control systems. Burglaries occurred during specific time windows when the building's access logs showed normal entry patterns but the physical evidence showed theft."

"They made themselves invisible," Sara said.

"They made themselves look normal to the algorithms," Emil corrected. "Which is the same thing in a smart building. No forced entry because they didn't need to force anything. They just... belonged, as far as the system could tell."

Sara studied the timeline. "Six weeks. Same timeframe as the pharmacy robberies ramping up. These could be different perpetrators using the same toolkit."

"Or proof-of-concept demonstrations," Emil said. "Teaching exercises to show how the methodology works across different contexts. Pharmacies, luxury apartments, what's next?"

"Service workers would have the access," Sara said slowly. "Cleaning services, maintenance, delivery. They're in these buildings all the time. The systems learn to recognize them as normal. And they're economically vulnerable—" She thought of the receptionist's voice, the resignation when she talked about employment discrimination. "—vulnerable enough to need supplemental income."

Emil pulled up a new screen showing dark web forum activity. "I found cross-references. NullGradient and another user called Adversary are active in the same communities. Both teaching methodology, both focused on surveillance systems. Linguistic analysis suggests they might be coordinating."

"Or both from the same place," Sara said. "Rosengård."

"Maybe. But Sara..." Emil turned to face her fully. "Even if we identify NullGradient, even if we connect them to these crimes, we're looking at an ecosystem. The tools are out there. The knowledge is spreading. We catch one person, ten more are already using the techniques they taught."

"So what do we do?"

Emil was quiet for a moment. "We try to understand the whole picture. Not just the criminals, but the system that creates them. Why someone with graduate-level computer science skills is teaching people how to rob pharmacies instead of working for Google."

Sara thought about the man in the café, about the young woman teaching adversarial ML to her friends, about the economic barriers and algorithmic discrimination that defined Rosengård's relationship to Malmö's smart city ambitions.

"Because Google wouldn't hire them," she said quietly. "Because the algorithms that are supposed to make hiring fair flagged them as too risky based on their postal code. Because the smart city is only smart for some people."

"Yeah," Emil said. "And because someone decided that if the system was going to exclude them anyway, they might as well learn to exploit it."

The city lights glittered outside Emil's window—Malmö in all its optimized, algorithmic glory. Somewhere out there, in Rosengård or Västra Hamnen or anonymous rooms connected by encrypted networks, people were teaching each other how to make that optimization obsolete.

Sara needed to find them. But more importantly, she needed to understand them. Because arrest wasn't going to solve a problem this systemic.

And systemic problems required systemic solutions, which were far beyond the mandate of the Economic Crime Division.

Still. Someone had to try.

"Let's focus on the apartment burglaries," Sara said. "They're the most recent, most trackable. Find the service workers, find the connection to NullGradient's tools, build the case from there."

Emil nodded and turned back to his screens. Sara watched the data flow—building access logs, dark web marketplace transactions, forum posts in three languages, the digital exhaust of a city that generated more data than it could protect.

Somewhere in that noise was a signal. Somewhere in Rosengård was a person or people who'd learned to weaponize marginalization. And somewhere in the gap between smart city rhetoric and economic reality was the reason why.

Sara just had to find the thread and follow it all the way through.

Even if it led to truths that law enforcement couldn't fix.
